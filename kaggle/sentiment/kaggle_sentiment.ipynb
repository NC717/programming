{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('http://fonts.googleapis.com/css?family=Source+Code+Pro');\n",
       "@import url('http://fonts.googleapis.com/css?family=Vollkorn');\n",
       "@import url('http://fonts.googleapis.com/css?family=Arimo');\n",
       "@import url('http://fonts.googleapis.com/css?family=Fira_sans');\n",
       "\n",
       "    div.cell{\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "    div.text_cell code {\n",
       "        background: transparent;\n",
       "        color: #000000;\n",
       "        font-weight: 600;\n",
       "        font-size: 12pt;\n",
       "        font-style: bold;\n",
       "        font-family:  'Source Code Pro', Consolas, monocco, monospace;\n",
       "   }\n",
       "    h1 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "\t}\n",
       "\t\n",
       "    div.input_area {\n",
       "        background: #F6F6F9;\n",
       "        border: 1px solid #586e75;\n",
       "    }\n",
       "\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200;\n",
       "        font-size: 30pt;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h2 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "        text-align: left;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200;\n",
       "        font-size: 16pt;\n",
       "        font-style: italic;\n",
       "        line-height: 100%;\n",
       "        color:#c76c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 1.5em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    } \n",
       "    h3 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200;\n",
       "        font-size: 14pt;\n",
       "        line-height: 100%;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 2em;\n",
       "        display: block;\n",
       "        white-space: wrap;\n",
       "        text-align: left;\n",
       "    }\n",
       "    h4 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-weight: 100;\n",
       "        font-size: 14pt;\n",
       "        color:#d77c0c;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    h5 {\n",
       "        font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200;\n",
       "        font-style: normal;\n",
       "        color: #1d3b84;\n",
       "        font-size: 16pt;\n",
       "        margin-bottom: 0em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "        white-space: nowrap;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Fira sans', verdana,arial,sans-serif;\n",
       "        line-height: 125%;\n",
       "        font-size: 115%;\n",
       "        text-align:justify;\n",
       "        text-justify:inter-word;\n",
       "    }\n",
       "    div.output_subarea.output_text.output_pyout {\n",
       "        overflow-x: auto;\n",
       "        overflow-y: scroll;\n",
       "        max-height: 50000px;\n",
       "    }\n",
       "    div.output_subarea.output_stream.output_stdout.output_text {\n",
       "        overflow-x: auto;\n",
       "        overflow-y: scroll;\n",
       "        max-height: 50000px;\n",
       "    }\n",
       "    div.output_wrapper{\n",
       "        margin-top:0.2em;\n",
       "        margin-bottom:0.2em;\n",
       "}\n",
       "\n",
       "    code{\n",
       "      font-size: 70%;\n",
       "    }\n",
       "    .rendered_html code{\n",
       "    background-color: transparent;\n",
       "    }\n",
       "    ul{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li li{\n",
       "        padding-left: 0.2em; \n",
       "        margin-bottom: 0.2em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    ol{\n",
       "        margin: 2em;\n",
       "    }\n",
       "    ol li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.5em; \n",
       "    }\n",
       "    ul li{\n",
       "        padding-left: 0.5em; \n",
       "        margin-bottom: 0.5em; \n",
       "        margin-top: 0.2em; \n",
       "    }\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "    .rendered_html :hover {\n",
       "       text-decoration: none; \n",
       "    }\n",
       "    .rendered_html :visited {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :focus {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .rendered_html :active {\n",
       "      text-decoration: none;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "    } \n",
       "    hr {\n",
       "      color: #f3f3f3;\n",
       "      background-color: #f3f3f3;\n",
       "      height: 1px;\n",
       "    }\n",
       "    blockquote{\n",
       "      display:block;\n",
       "      background: #fcfcfc;\n",
       "      border-left: 5px solid #c76c0c;\n",
       "      font-family: 'Open sans',verdana,arial,sans-serif;\n",
       "      width:680px;\n",
       "      padding: 10px 10px 10px 10px;\n",
       "      text-align:justify;\n",
       "      text-justify:inter-word;\n",
       "      }\n",
       "      blockquote p {\n",
       "        margin-bottom: 0;\n",
       "        line-height: 125%;\n",
       "        font-size: 100%;\n",
       "      }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading the format for the notebook\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir('../../notebook_format')\n",
    "from formats import load_style\n",
    "load_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Kaggle knowledge competition: movie review sentiment analysis. [homepage](https://www.kaggle.com/c/word2vec-nlp-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv( 'labeledTrainData.tsv', delimiter = '\\t' )\n",
    "test  = pd.read_csv( 'testData.tsv', delimiter = '\\t' )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove tags or markup (e.g. <br> <\\br> )\n",
    "train['review'] = train['review'].apply( lambda s: BeautifulSoup(s).get_text() )\n",
    "test['review']  = test['review'].apply(  lambda s: BeautifulSoup(s).get_text() )\n",
    "\n",
    "# extract the training and testing's data/label\n",
    "X_train = train['review']\n",
    "y_train = train['sentiment']\n",
    "X_test  = test['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Try \n",
    "\n",
    "Use the most simplest approach: remove english stopwords, bag of words + default logistic regression and naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert both sets' text column to document-term matrix\n",
    "vect1 = CountVectorizer( stop_words = 'english' )\n",
    "X_train_dtm = vect1.fit_transform(X_train)\n",
    "X_test_dtm  = vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train two popular model for text classification\n",
    "# 1. mutinomial naive bayes model\n",
    "# 2. logistic regression, 10-fold cross validation to determine \n",
    "# the best regularization `C`\n",
    "\n",
    "# tune the regularization/error term for logistic regression\n",
    "param_dict = { 'C': [ 0.001, 0.01, 0.1, 1, 10, 25 ] }\n",
    "    \n",
    "logreg = LogisticRegression()    \n",
    "grid_logreg = GridSearchCV( \n",
    "    logreg, \n",
    "    param_grid = param_dict, \n",
    "    cv = 10,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    verbose = 1\n",
    ")\n",
    "    \n",
    "nb = MultinomialNB()\n",
    "\n",
    "models = [ nb, grid_logreg ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_models( models, X_train, y_train ):\n",
    "    \"\"\"\n",
    "    Train a bunch of models\n",
    "       \n",
    "    TODO : add more models\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models : list\n",
    "        a list of specified models to train\n",
    "    \n",
    "    X_train, y_train : numpy array\n",
    "        training data and its label\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    models_dict : dictionary\n",
    "        keys are the model's name, values are the corresponding trained models object.\n",
    "        To be exact, if the model uses default parameters, then the key will only be \n",
    "        the model's name, but if the model uses grid/random \n",
    "        search to find the best possible parameter, then the best parameters will\n",
    "        also be tagged along with the model's name. e.g. LogisticRegression-C_0.1,\n",
    "        means the best parameter is C 0.1 for the logistic regression\n",
    "    \"\"\"\n",
    "    \n",
    "    # train all the models\n",
    "    # for scikit learn model, it's simply .fit\n",
    "    for model in models:\n",
    "        model.fit( X_train, y_train )\n",
    "        \n",
    "    # get the models' name\n",
    "    model_names = []\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "\n",
    "        # if it's a sklearn's CV model, search deeper for model name\n",
    "        # and it's best estimated parameter            \n",
    "        if model_name in ( 'GridSearchCV', 'RandomizedSearchCV' ):\n",
    "                        \n",
    "            # best parameter obtained by the grid search\n",
    "            strings = []\n",
    "            params = model.best_params_           \n",
    "            for key, value in params.items():\n",
    "                string = str(key) + ' = ' + str(value)\n",
    "                strings.append(string)\n",
    "            \n",
    "            # concatenate the model's name and the best parameter\n",
    "            param_strings = ', '.join(strings)\n",
    "            best_model = model.best_estimator_\n",
    "            model_name = best_model.__class__.__name__ + ': ' + param_strings\n",
    "        \n",
    "        model_names.append(model_name)\n",
    "        \n",
    "    models_dict = { name: model for name, model in zip( model_names, models ) }\n",
    "    return models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "models_dict = train_models( models = models, X_train = X_train_dtm, y_train = y_train )\n",
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_probabilities( models_dict, X_test, write_submission = False, \n",
    "                           test_id = None, column_names = [ 'id', 'predictions' ] ):\n",
    "    \"\"\"\n",
    "    For each model, predict the probability of the test set\n",
    "    and store the result in one single dataframe. In the mean time, you\n",
    "    can also specify whether to write the prediction result to .csv files\n",
    "    \n",
    "    TODO 1: make it work with models from other commonly used library\n",
    "    TODO 2: extend it to muti-class problems\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    models_dict : dictionary\n",
    "        dictionary of already fitted models, where the keys are the model's name\n",
    "        value is the already trained model object\n",
    "        \n",
    "    X_test : np-array\n",
    "        test data of the fitted models\n",
    "        \n",
    "    write_submission : boolean (default: False)\n",
    "        if True, then each model's prediction will be written to a .csv file,\n",
    "        all of which are stored in a 'submission' + datetime folder (overwrite if the folder\n",
    "        already exists). Each .csv file will contain two column, the first being\n",
    "        the test set's id and the second being the model's predicted probability\n",
    "    \n",
    "    test_id : np-array\n",
    "        specify test set's id if write_submission is True\n",
    "    \n",
    "    column_names : list/tuple, default: [ 'id', 'predictions' ]\n",
    "        column name for the submission\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    predictions : DataFrame\n",
    "        each column is the predicted probability of the test data for each model\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a folder name 'submission' + datetime to store the predicted result\n",
    "    # it'll over-write the existing file if it exists\n",
    "    if write_submission:\n",
    "        folder = 'submission' + str( datetime.now() )\n",
    "        if os.path.exists(folder):\n",
    "            shutil.rmtree(folder)\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    predictions = np.zeros( ( X_test.shape[0], len(models_dict) ) )   \n",
    "    for index, ( name, model ) in enumerate( models_dict.items() ):        \n",
    "        pred = model.predict_proba(X_test)[ :, 1 ]\n",
    "        predictions[ :, index ] = pred\n",
    "        \n",
    "        if write_submission:\n",
    "            output = pd.DataFrame({ 'id': test_id, 'prediction': pred })\n",
    "            output.columns = column_names\n",
    "            output.to_csv( os.path.join( folder, name + '.csv' ), index = False )\n",
    "    \n",
    "    predictions = pd.DataFrame( predictions, columns = list( models_dict.keys() ) )    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LogisticRegression-C_0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.980770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.334912e-10</td>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.846241e-02</td>\n",
       "      <td>0.621370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MultinomialNB  LogisticRegression-C_0.1\n",
       "0   1.000000e+00                  0.980770\n",
       "1   8.334912e-10                  0.004839\n",
       "2   3.846241e-02                  0.621370"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression 0.94127\n",
    "# naive bayes 0.89415\n",
    "\n",
    "# if `write_submission` is False then you do not need to specify\n",
    "# the `test_id` nor `column_names`\n",
    "predictions = predict_probabilities( \n",
    "    models_dict = models_dict, \n",
    "    X_test = X_test_dtm,\n",
    "    write_submission = True,\n",
    "    test_id = test['id'],\n",
    "    column_names = [ 'id', 'sentiment' ]\n",
    ")\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Try\n",
    "\n",
    "Include n-gram (1 and 2-gram to be exact), stemming (e.g. running will be converted to run) and use cross validation to determine the best regularization for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    \"\"\"pass into the tokenizer argument of Count\"\"\"\n",
    "    stemmed = [ porter.stem(word) for word in text.split() ]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer( \n",
    "    stop_words = 'english', \n",
    "    tokenizer = tokenizer_porter, \n",
    "    ngram_range = ( 1, 2 ),\n",
    "    min_df = 2\n",
    ")\n",
    "X_train_dtm = vect2.fit_transform(X_train)\n",
    "X_test_dtm  = vect2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LogisticRegression-C_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.999129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.183532e-13</td>\n",
       "      <td>0.005406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.991036e-01</td>\n",
       "      <td>0.980235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MultinomialNB  LogisticRegression-C_1\n",
       "0   1.000000e+00                0.999129\n",
       "1   6.183532e-13                0.005406\n",
       "2   9.991036e-01                0.980235"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = train_models( X_train = X_train_dtm, y_train = y_train )\n",
    "\n",
    "# logistic regression 0.94474\n",
    "# naive bayes 0.92292\n",
    "predictions = predict_probabilities( \n",
    "    models_dict = models_dict, \n",
    "    X_test = X_test_dtm,\n",
    "    write_submission = True,\n",
    "    test_id = test['id'],\n",
    "    column_names = [ 'id', 'sentiment' ]\n",
    ")\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Try\n",
    "\n",
    "Use tf-idf instead of bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_vect1 = TfidfVectorizer( \n",
    "    stop_words = 'english', \n",
    "    tokenizer = tokenizer_porter, \n",
    "    ngram_range = ( 1, 2 ),\n",
    "    min_df = 2\n",
    ")\n",
    "X_train_dtm = tf_vect1.fit_transform(X_train)\n",
    "X_test_dtm  = tf_vect1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   33.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LogisticRegression-C_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.864180</td>\n",
       "      <td>0.996484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.208051</td>\n",
       "      <td>0.037363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.605011</td>\n",
       "      <td>0.902219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MultinomialNB  LogisticRegression-C_25\n",
       "0       0.864180                 0.996484\n",
       "1       0.208051                 0.037363\n",
       "2       0.605011                 0.902219"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict = train_models( X_train = X_train_dtm, y_train = y_train )\n",
    "\n",
    "# logistic regression 0.95386\n",
    "# naive bayes 0.93842\n",
    "predictions = predict_probabilities( \n",
    "    models_dict = models_dict, \n",
    "    X_test = X_test_dtm,\n",
    "    write_submission = True,\n",
    "    test_id = test['id'],\n",
    "    column_names = [ 'id', 'sentiment' ]\n",
    ")\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: stacking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manually weighted average : 0.95501\n",
    "pred = np.average( predictions.values, axis = 1, weights = ( 0.4, 0.6 ) )\n",
    "output = pd.DataFrame({ 'id': test['id'], 'sentiment': pred })\n",
    "output.to_csv( 'test.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Kaggle Use Google's Word2Vec for movie reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial)\n",
    "- [Blog on Natural Language Processing in a Kaggle Competition for Movie Reviews](https://jessesw.com/NLP-Movie-Reviews/)\n",
    "\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/forums/t/14966/post-competition-solutions"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
