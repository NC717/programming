---
title: "Marketing Analytics"
author: "Ming-Yu Liu"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: pygments
---

<style type="text/css">
p{ /* Normal  */
   font-size: 18px;
}
body{ /* Normal  */
   font-size: 18px;
}
td {  /* Table  */
   font-size: 14px;
}
h1 { /* Header 1 */
 font-size: 32px;
}
h2 { /* Header 2 */
 font-size: 26px;
}
h3 { /* Header 3 */
 font-size: 22px;
}
code.r{ /* Code block */
  font-size: 14px;
}
pre { /* Code block */
  font-size: 14px
}
</style>

#### marketing_analysis : (on hold : add customer lifetime value)

Conducting customer segmentations using RFM (Recency, Frequency, Monetary Value) method.

- View [[R markdown](http://ethen8181.github.io/Business-Analytics/marketing_analysis/marketing_analysis.html)]

----


The domain of marketing analysis is huge, topics can range from social network analysis, real time bidding, campaign optimization and so on. Though at the heart of the marketing lies some techniques that address fundamental questions that businesses all wish to be to able answer well.

1. **Segmentation:** Allows businesses to identify who are my customers or so called target audiences? 
2. **Scoring Models:** Targeting the right customers, that is which customers should I spend the most marketing budget on?
3. **Customer Life Time Value:** What's the future value of my customers? That way the company will be able to concentrate the most on those that will be worth the most.


# Segmentation

Each company may have stored a large pool of data for each of their customers based on hundreds of indicators. Though rich in quantity, it is often hard to directly use it to obtain the insights needed. Thus, segmentation is implemented to transform your data into something that is clear and usable. 

A more intuitive way when referring to the purpose of segmentation is: You can't treat every single one of your customers the same way, charge them the same price or communicate in the same benefits. But as that being said, you can't treat each and every customer individually, as that will be way too costly. So a good segmentation is to find the right balance between simplifying it to make it usable and not simplifying it much so that it is still valuable.

Knowing what segmentation does, we now have to choose the variables that are suitable to perform the segmentation on. While the suitable variables will still differ according to the goals that you what to accomplish, there are three variables that have proven are often times useful to predict customer profitability. Namely: 

- **Recency:** Indicates when the customer made his/her last purchase. If a customer has lapsed and has not made a purchase for a long period of time he/she may have lost interest. Or worst, switch to your competition.
- **Frequency:** Refers to the number of purchases made in the past. More could possibly means that the more likely additional purchases will occur in the future.
- **Monetary Value:** The amount of money spent on average at each purchase occasion. Obviously, the more money a customer spent the more valuable he/she is to the company.

Segmentation performed by these three varaibles are often times referred to as RFM segmentation.

After saying that much, let's start looking at our dataset at hand, a selling customer purchase record for a retailer. Note that the original text file data does not contain a header. And the three columns represents customer id, purchase amount and date of purchase ( in year-month-day format ) respectively. 

```{r, warning=FALSE, message=FALSE}

# environment setting
library(grid)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(lubridate)
library(data.table)
setwd("/Users/ethen/Business-Analytics/marketing_analysis")

# load data, reset column names and convert to date type
# also create a year column for later convenience
data <- fread( "purchase.txt", sep = "\t", header = FALSE  )
setnames( data, c( "customer_id", "purchase_amount", "purchase_date" ) )
data[ , purchase_date := ymd(purchase_date) ] 
data[ , purchase_year := year(purchase_date) ]
data

```

Since recency value isn't built-in with the dataset we'll have to do it ourselves. We're going to compute the time difference between the `purchase_date` and the very last day (plus 1 day) recorded in the dataset. After obtaining the day difference we'll convert it back to numeric type.

```{r}

last <- max(data$purchase_date) + days(1)
data[ , recency := difftime( last, purchase_date ) %>% as.numeric() ]
summary(data)

```

Using a quick summary function on the dataset, we can see that it consists of customer purchase
from January 2005 to the last day of 2015. The mean of the `purchase_year` tells that most purchases have been made during 2011 and the average recency value is around 1632 days.

Next, we'll compute the RFM value for each customer. Despite that that are `r nrow(data)` rows in the dataset, there's actually only `r length( unique(data$customer_id) )` unique customers for this entire dataset. To be explicit, we'll compute:

- `avg_amount` The average amount spent by every customer to represent monetary value. 
- `first_purchase` and `recency` The first time the customer bought something and the last time (closest to today) they bought something.
- `frequency` How often did each customer purchased at this retail store. 

Data.table allows you to compute all that in one concatenated command. After computing the value, histogram can be used to look at the values' distribution. 

```{r, fig.height=6, fig.width=10, message=FALSE}

rfm1 <- data[ , .( recency 	  	  = min(recency),
				   first_purchase = max(recency),
				   frequency  	  = .N, 
				   avg_amount 	  = mean(purchase_amount) ), by = customer_id ]
# distibution
grid.arrange( ggplot( rfm1, aes( avg_amount ) ) + geom_histogram(),
			  ggplot( rfm1, aes( frequency )  ) + geom_histogram(), ncol = 2,
			  top = textGrob( "Variable Distribution" ) )

```

`avg_amount`'s extremely skewed histogram tells us that most people spent very few for each purchase and probably requires some tuning if we're to use them for building a predictive model later on. We can think about this in an intuitive way. Someone who spends 15 dollars on average generates three times the revenue for the company compared with someone who only spends 5 dollars. But what about two customers who spent 310 and 320 dollars respectively? You'll notice the difference in purchase amounts for these two groups are 10 dollars for both occasions, meaningly that they will treated the same in distance computations if we do not do something about them. The same goes for `frequency`.

Moving on to computing our segmentation. To perform this, we'll be using a set of rules. Customer dataset is changing at a continous bases; old customer disappear, new customers are acquired. Thus, using a statistical (machine-learning) segmentation method ( e.g. clustering algorithms ) for this kind of situatation may not be so cost-effective, as you will probably have to update the segmentation the moment you've created it. Another reason that statistical segementation may not be applicable for this circumstances is that perhaps customer behaviors are seasonal. The best segmentation solution from a statistical viewpoint will most likely vary if you run your analysis at different time point, making them uncomparable. To put it all together, how can you target your actions on one of the segment if the very definition of that segment keeps on fluctuating over time? For this reason, we'll be performing our customer segmentation by a set of simple rules and these rules are fixed for some period of time, update it only after a few quarters of years depending on the needs of the business.

The indicator of determining which customer should receive more attention is based on how much they spent and how likely are they going to buy from us in the future. One basic criteria of determining whether customer will buy from us in the future is **recency**. Someone who has made a purchase a few weeks is far more likely to buy from the company again ( compared to someone who has made their lasy purchase many years ago ).

Hence we'll first divide our customers into four main groups based on **recency**. We define a customer to be `active` if they have bought from us within the last year. `warm` if they have made a purchase between 1 to 2 years ago. `cold` is a customer has made a purchase between 2 to 3 years ago. For those who haven't purchased anything for more than three years, we will label them as `inactive`. ( Of course, you should change these cutoff values for each segment depending on your needs ).

After splitting our customers into four main segments, we'll also perform further segmenting on the `active` and `warm` segments. We'll take the customers from these segments and put the new ones, those with the history of making their first purchase within the same timespan into the segment of `new active` and the rest as `old active`. e.g. the active customer is defined as those who have made their last purchases within this year, if that customer made their first purchase within this year, a.k.a same timespan, then they would be classified as new. 

Next, we'll take a step further and split these two sub-groups into four sub-sub-groups based on how many money they've spent on average. For this cutoff value we decided to use 100 based on the 90 percent quantile. Again, tune this parameters based on your needs. 

```{r}

quantile( rfm1$avg_amount, probs = seq( 0, 1, 0.1 ) )

```

This converts our segmentation for the original `active` segment to four segments `new active low`, `new active high`, `old active low` and `old active high`. We'll also apply the exact same idea to the `warm` segment. Resulting in a total of 10 segments.

Hopefully all that wordy description will become much more clear if you looked at the code.

The function [`Segmentation`][Segmentation] for creating this segmentation is not printed to conserve space. It takes the rfm data and creates manual segmentation based on the recency criteria first that splits customer's into inactive, cold, warm and active based on the three recency cutoff value. Then further splits the warm and active segment into four sub-groups each based on the amount cutoff value and whether they have made their first purchase within the same timespan with respect to the "baseline". This will classify each of the two original segments further into new high, new low, old high and old low. Input parameters:

- `data` rfm segmentation data, must have five columns exactly named as customer_id, recency, first_purchase, frequency and avg_amount. The order of the column doesn't matter.
- `inactive` Customers whose recency are higher than this value will be classified as inactive customers. Note that the unit of recency is "days".
- `cold` Same functionality as above, except it's the cutoff value for cold customers.
- `warm` Same functionality as above, cutoff value for splitting the warm and active customers.
- `amount` Cutoff value for splitting the warm and active customers further into high and low average purchased amount.
- The function returns the original rfm data and adds a new segment column to it. It also sorts the order of the rows by customer id. 

The next code chunk uses the function, prints out data and the proportional distribution of the segment column.

```{r}

# segmentation parameters 
inactive <- 3 * 365
cold 	 <- 2 * 365
warm 	 <- 365 
amount   <- 100

source("/Users/ethen/Business-Analytics/marketing_analysis/code/marketing_functions.R")
rfm1 <- Segmentation( data = rfm1, inactive = inactive, 
					  cold = cold, warm = warm, amount = amount )
rfm1

# segment proportional distribution 
round( table(rfm1$segment) / sum( table(rfm1$segment) ), 2 )

```

We can directly identify that around half of our customers are "inactive", meaning that they have not not purchased anything for at least three years after their last purchase. If we wish to identify the profile or characteristics of each segment, we can calculate the average number of each variable ( except for customer id of course ).

```{r}

rfm1[ , lapply( .SD, mean ), by = segment, .SDcols = -c("customer_id") ]

```

However, the most important usage of these segmentations is that you go back in time and check how many customers were in each customers a year or two years ago and see how things have evolved. By doing so, we'll be able to analyze trends such as are there increase in the number of high value customers? Or have you added more new customers than the year before, etc. Answers to these questions will evaluate the company's overall performance so far and see whether there's room for improvement.

One caveat for doing this is that: The customers that appeared in your dataset today may not even existed a year or even a few weeks ago. Thus when we're using today's dataset to go back in time we have to make sure that we properly take care of those non-existent customers as we'll see later.

The next chunck will obtain the rfm segmentation `rfm2`. This serves as our retrospective segmentation where we'll go back in time by *one year* and obtain the segmentation at that time using the dataset we have today. 

```{r}

# retrospective customer segmentation 
rfm2 <- data[ recency > 365, 
			  .( recency 	  	= min(recency) - 365,
				 first_purchase = max(recency) - 365,
				 frequency  	= .N, 
				 avg_amount 	= mean(purchase_amount) ), by = customer_id ]

rfm2 <- Segmentation( data = rfm2, inactive = inactive, 
					  cold = cold, warm = warm, amount = amount )
rfm2

# segment proportional distribution 
round( table(rfm2$segment) / sum( table(rfm2$segment) ), 2 )

```

Now that we've obtain `rfm1` the segmentation for today and `rfm2` the segmentation for a year ago, the primary question we want to answer is: which segment should we concentrate on or in other words, which customer segmentation will be most beneficial to the future success of the company and are the ones that we should be allocating more resources on? Let's dive into that in the next code chunk.

1. `revenue_per_customer` Aggregate each customer's total purchased amount for the current year.
2. `revenue_predicted` Merge the previous year's segment with this year's revenue, this is essentially examining how did our customers from last year performed this year. If a customer has not purchased anything for the current year then they will not show up in the revenue1 data ( resulting in NA values ) and we'll replace these values with 0.
3. `revenue_summary`: The average revenue that you would expect from each segment's customer in the next time period ( in our example, next year ) and the expected total revenue generated by each segment.

```{r, fig.width=10, fig.height=6}

# 1.
revenue_per_customer <- data[ purchase_year == 2015, 
				  			  .( revenue = sum(purchase_amount) ), by = customer_id ]
# 2.
revenue_predicted <- merge( rfm2, revenue_per_customer, by = "customer_id", all.x = TRUE )
revenue_predicted[ is.na(revenue), revenue := 0 ]

# 3. 
revenue_summary <- revenue_predicted[ , .( avg_revenue 	 = mean(revenue),
								  		   total_revenue = sum(revenue) ), by = segment ] %>%
				   arrange( desc(total_revenue), desc( avg_revenue) )
revenue_summary

```

From the printed result, we can infer interesting facts about our customer segment. The average revenue column of the `revenue_summary` data.table tells us that each "`r revenue_summary$segment[2]`" customer is worth approximately `r round(revenue_summary$avg_revenue[2])` to our company ( or you can say contribute that much do our company if the previous statement sounded a bit rude ... ). This is a lot higher than a "`r revenue_summary$segment[ revenue_summary$segment == "inactive" ]`" customer. However, when we switched to the total revenue column, it tells us that `r revenue_summary$segment[1]` is the segment that generated the most revenue in total! If we looked back at our original `rfm2` segmentation ( scroll back up please ), we can also see that the customer size of this segment is around 20 percent and the second highest segment `r revenue_summary$segment[2]` represents only about 3 percent of our entire customer. This is a good example where small segments in terms of number of customers that generates a huge share of revenues. And it's directly of telling us that customers should not be treated equally as there are just some that contributes more to the overall revenue.

**Section Takeaways:** Use statistical segmentation when the segment you wish to obtain is a "oneshot" thing or use it as a exploratory tool when you're not famaliar with the overall objective.

# Customer Life Time Value

Let's envisage the following scenario. You're company lauched a new customer acquistion campaign including hard-discounts, online-keywords, e-mail campaigns etc. In the end, it only turned out to be a minor success. Sure, the company has in fact acquired new customers and generated new sales, but the sales generated does not even cover the cost of the campaign. The supervisor in charge of the campaign , however, argued that the newly acquired customers will remain loyal to the company and generate additional sales in the future. In a sense this campaign is said to be an investment for the future. Is this true? or is it just another excuse for the campaign's bad performance? 

This problem scenario is the whole point of measuring **Customer Life Time Value** (CLTV), to prove or disprove whether acquiring these new customers is a good investment. 

**Sources:**

You can find all the source code [here](https://github.com/ethen8181/Business-Analytics/tree/master/marketing_analysis/code). marketing_analysis.R contains the documentation's general scripts and marketing_functions.R contains the functions that were sourced in and used with this documentation.

If you happened to have any comments, feedbacks of any sort, Feel free to file them [here](https://github.com/ethen8181/Business-Analytics/issues)!


# R Session Information

```{r}

sessionInfo()

```

[Segmentation]: https://github.com/ethen8181/Business-Analytics/tree/master/2_marketing_analysis/code/marketing_functions.R


