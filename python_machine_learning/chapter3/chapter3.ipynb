{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the iris datset, the target is already stored as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data[ :, [ 2, 3 ] ]\n",
    "y = iris.target\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_test_split` Split the dataset into 70 percent training and 30 percent testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = 0.3, random_state = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler` use .fit and .transform the perform the feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_sd = sc.transform(x_train)\n",
    "x_test_sd  = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sklearn's Perceptron API.\n",
    "\n",
    "- .fit( dataset, target )\n",
    "- .predict( dataset ), returns in np.array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassfied samples 4\n",
      "Accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron( n_iter = 40, eta0 = 0.1, random_state = 0 )\n",
    "ppn.fit( x_train_sd, y_train )\n",
    "y_pred = ppn.predict( x_test_sd )\n",
    "print ( \"Missclassfied samples %d\" % ( y_test != y_pred ).sum() )\n",
    "print ( \"Accuracy %.2f\" % accuracy_score( y_test, y_pred ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Sigmoid function. Takes real number values as input and transform them into values in the range [ 0 , 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGbZJREFUeJzt3Xl0ldW5x/HvYyKCE4gD1woWFFBRwAmlupQotlJswS5v\nW6f2qqtKrWjbJZaLei/YyeJURaxaBq21llKqFocriiXiEotYEBUBwYoioiCgzEPIc//YB4k5GU5C\ncvb7nvP7rPWuk5O8CQ+Q5Heevd+9X3N3REREqtotdgEiIpI8CgcREcmicBARkSwKBxERyaJwEBGR\nLAoHERHJUhq7gF1hZroOV0SkEdzd6vp46jsHd0/8MXz48Og1FEqdaahRdarOpB+5SH04iIhI01M4\niIhIFoVDHpSVlcUuISdpqDMNNYLqbGqqM/8s1/GnJDIzT3P9IiIxmBle6BPSIiLS9BQOIiKSReEg\nIiJZFA4iIpJF4SAiIlkUDiIikkXhICIiWRQOIiKSJUo4mNl4M/vYzN6o45xRZrbIzOaa2XH5rE9E\npNjF6hweAPrV9kEz6w90dvcuwBXAvfkqTEREIoWDu78IrKnjlAHAHzLnzgTamFm7fNQmIiLJvdnP\nIcDSKs8/ANoDH8cpR0Rk17lDZSVs3559VH//wQdDacTf0EkNB4Dqm0LVuMPeiBEjPn+7rKysoHZF\nFJHmUVEBn332xWP9eti4MfvYtCn7+dat4di2rfbHmt5XUQFmUFKSfey22xefz5oVAqIplJeXU15e\n3qDPibYrq5l1BJ5w9+41fOw+oNzdJ2SeLwD6uPvH1c7TrqwiRc4dPv0UPv44HCtWZD+uWAFr1uwM\ngk2boHXrnUebNrD33rDnnl88WrXKfl/LlrDHHrD77tCiRXis+nZdj6WlIRxiy2VX1qR2DpOBwcAE\nM+sNfFo9GESkeGzcCAsXwuLFsGTJzuO998JjSQm0axeOgw7a+XjsseHxoINgv/1CCLRuHYIgCb+k\nkyxK52Bmfwb6AAcQ5hGGA7sDuPv9mXNGE65o2gBc6u6za/g66hxECsi2bfDmm/DGG/DWWzuPZcug\nc2fo2hU6dgzHl7+887F168iFp0wunYNu9iMi0SxbBi+8ADNnhjH2uXPDL/yePaFbt3AcfTQcfnjc\nydlCo3AQkURZvRqefRamTQvH6tVw+unwla9Ar15wwgmwzz6xqyx8CgcRie6dd2Dy5HDMng19+kDf\nvnDGGXDMMeEqHckvhYOIRLFiBUyYAA89FIaOvvlNGDAghEKrVrGrE4WDiOTN9u3w1FMwdixMnx7C\n4PvfDx1CSUns6qSqNF/KKiIpsW4dPPAAjBoFbdvCVVfBI4+Ey0UlvRQOItIoq1bBLbeETqFvX/jj\nH6F3b60fKBSaChKRBlm3Dn7+czjiCFi7NkwyT5wYrjhSMBQOhYOI5KSiAu66KyxGe/vtsDbh3nvD\nIjQpPBpWEpF6zZwJgwbBgQfC1KnQPWtHNCk0CgcRqdVnn8H118Ojj8Ltt8MFF2joqFhoWElEajR1\nati6Yts2mDcPLrxQwVBM1DmIyBdUVMDw4fDgg2ERW9++sSuSGBQOIvK5998PQ0f77BOuQmqnm/MW\nLQ0riQgAzz0XNr8bOBCeflrBUOzUOYgIY8fCjTfCX/8adkkVUTiIFLHKyp2hMH16uJmOCCgcRIrW\n5s1wySWwdCnMmBHWMIjsoDkHkSK0aVPYNXX7dnj+eQWDZFM4iBSZzZvh3HPhgAPgz3+Gli1jVyRJ\npHAQKSI7gqFt27CGQfdlltooHESKxObN8K1vQevWYXttBYPURXeCEykC27fDeefB7ruHoSQFQ3HT\nneBEBIAhQ8K9F555RsEgudG3iUiBGz06hMKMGdCiRexqJC0UDiIF7Mkn4de/hpdegv32i12NpInC\nQaRAzZ4Nl14aAqJTp9jVSNroaiWRArRyZbhk9b774OSTY1cjaaSrlUQKTGUl9O8PPXvCyJGxq5Ek\nyuVqJXUOIgXmN7+B9evhl7+MXYmkmeYcRArICy/AqFHw6qthTYNIY6lzECkQH38MF10Ubu/Zvn3s\naiTtNOcgUgAqK6Ffv3Ant1/9KnY1knSacxApEr/7HaxbBzfdFLsSKRTqHERS7p13wuWqL70ERxwR\nuxpJA3UOIgWushIuuwyGDVMwSNNSOIik2D33QEUF/OQnsSuRQqNhJZGU2jGcNGMGdO0auxpJEw0r\niRSoHcNJN9ygYJDmoXAQSaFx42DbNrjmmtiVSKHSsJJIyqxaBd26wbPPhv2TRBoql2ElhYNIygwa\nBHvsEbbJEGkM3SZUpMC88gpMngzz58euRAqd5hxEUmL7drjqqrANd5s2sauRQqdwEEmJsWOhZUv4\n3vdiVyLFQHMOIinwySdhEnrqVOjRI3Y1knaakBYpEFdfHR7vvjtuHVIYFA4iBWDRIvjKV2DBAjjg\ngNjVSCHQCmmRAjBsGAwZomCQ/FLnIJJgL78M3/kOvP02tGoVuxopFOocRFLMHa67Dn7xCwWD5J/C\nQSSh/v53WLtWl65KHFohLZJA27bB0KFw111QUhK7GilG6hxEEmj8eDj0UDj77NiVSLHShLRIwmze\nDF26wKOPQq9esauRQqQJaZEUGjMGjj9ewSBxqXMQSZBNm6BzZ3jySTjuuNjVSKFS5yCSMvfdB717\nKxgkPnUOIgmxYUPoGp59Frp3j12NFDJ1DiIp8rvfwemnKxgkGdQ5iCTAunWha5g2LWzNLdKc1DmI\npMTo0XDWWQoGSQ51DiKRrV8Phx0G06fDkUfGrkaKgToHkRT4/e+hrEzBIMmizkEkoi1bQtegdQ2S\nT+ocRBLuwQfh2GMVDJI86hxEIqmogK5d4eGH4ZRTYlcjxUSdg0iCTZgQdl5VMEgS6X4OIhFUVsLN\nN8Odd8auRKRm6hxEInj8cdhrr7C2QSSJFA4ieeYOv/41XH89WJ2jviLxKBxE8mzatLDJ3oABsSsR\nqZ3CQSTPbrsNrr0WdtNPnySYLmUVyaM334SvfhXefRdatoxdjRQrXcoqkjC33w6DBysYJPnUOYjk\nyYcfwjHHwKJFsP/+sauRYqbOQSRB7r4bLr5YwSDpoM5BJA/WrYNOneCVV8JGeyIxqXMQSYhx4+DM\nMxUMkh7qHESaWUUFHH44TJoEvXrFrkZEnYNIIkyaBB07KhgkXRQOIs3IHW69FYYMiV2JSMPkvCur\nme0FXAQcA5QALYFKYD3wT+Cv7l7ZHEWKpFV5OWzcCOecE7sSkYbJac7BzL4KdAOedPd3qn3MgJ7A\nWcBUd3+tOQqtpS7NOUiinXMOfOtb8IMfxK5EZKdc5hzqDQczawm0d/fFOfyB3d39jYaV2XgKB0my\nefOgb19YskQroiVZmmRC2t03Vw0GM7vMzEozbx9pZi2qnJtTMJhZPzNbYGaLzGxoDR8vM7PPzGxO\n5rgxl68rkiTaKkPSrDF3gjsCmGhmg4APgTHAf+X6yWZWAowmDEMtA2aZ2WR3n1/t1BfcXZsaSyot\nXx5u6LNoUexKRBqnMVcr9QR+AowHDiRMSDfEScBid1/i7tuACcDAGs7TbVAktUaNgosu0lYZkl6N\n6RyecPf3zex7hA7gpgZ+/iHA0irPPwBOrnaOA6eY2VxCdzHE3d9qRK0iebduHYwZE7bKEEmrBoeD\nu9+Tefw0ExD9gIY0z7nMIM8GOrj7RjP7OvA40LWmE0eMGPH522VlZZSVlTWgFJGmN368tsqQZCkv\nL6e8vLxBn5PL1Up7APu4+yf1fjGzQ939/XrO6Q2McPd+mefDgEp3H1nH57wLnODuq6u9X1crSaJU\nVEDnzvCXv8DJ1fthkYRoqquVtgC9zexCM2tVyx+0n5ldAXw5h7peBbqYWcfMlU7fBSZX+3rtMusn\nMLOTCCG2OvtLiSTLpElw6KEKBkm/nIaV3P1JMzsY+KmZHURYHb07sB3YSJg3GOPun+XwtSrMbDAw\nhbDSepy7z89c/YS73w/8J3ClmVVkvv75Df+rieTXjq0yqox0iqRWg3dlNbPOwAhCONzm7rOaoa5c\na9GwkiTGtGlw5ZXw1luwm3YtkwTLZVgpp87BzM4A3nb3ZcB5wFXAAcClZtbK3afvcrUiKXfbbXDt\ntQoGKQy57q1khMVvhwB9gJcJwz2zge+6+9jmLLKOutQ5SCJoqwxJkybrHDK/gRcAC8yss7v/X2bP\npeOAjmZ2NrDd3afuctUiKaStMqTQNGYR3LNm9gDwHLAB2OruU5q2LJH0WL4cHnsMFte7NaVIejTq\nNqFm1oZwb4cK4MHM5a55p2ElSYJhw8Kq6NGjY1cikpsm2bI7yRQOEtvatWEl9KxZ0KlT7GpEcqN7\nSIs0s/vvh699TcEghUedg0gjbdkSuoannoJjj41djUju1DmINKOHH4bu3RUMUpjUOYg0QmUldOsG\n994LZ5wRuxqRhlHnINJM/v532Hdf0A7xUqgUDiIN5A4jR8LQoWC6X6EUKIWDSANNnw6rV8O558au\nRKT5KBxEGmjkSLjuOigpiV2JSPPRhLRIA7z+OvTrB//+t/ZRkvTShLRIE7vlFvjxjxUMUvjUOYjk\naMkSOOGE0DW0bh27GpHGU+cg0oTuuAN+8AMFgxQHdQ4iOfjoo7Dobd48OPjg2NWI7Bp1DiJN5Pbb\n4eKLFQxSPNQ5iNRj5Uo44ohwpVL79rGrEdl16hxEmsAdd8D55ysYpLiocxCpw6pV0LUrzJkDhx4a\nuxqRpqHOQWQX3XknnHeegkGKjzoHkVqsWQNduugWoFJ41DmI7IJRo2DAAAWDFCd1DiI1WLMmzDXM\nmBG6B5FCos5BpJFuvRUGDlQwSPFS5yBSzUcfwdFHw2uvQYcOsasRaXq5dA4KB5FqBg+GFi3C+gaR\nQqRwEGmgd9+FE0+EBQvgwANjVyPSPDTnINJAw4eHzkHBIMWuNHYBIkkxbx5MmQKLFsWuRCQ+dQ4i\nGTfeCD/7Gey7b+xKROJT5yBCWM/w6qvwyCOxKxFJBnUOUvQqK8N9oW++GVq1il2NSDIoHKToPfww\n7LYbXHhh7EpEkkOXskpRW78+3Mjnb3+D3r1jVyOSH7qUVaQeI0dCWZmCQaQ6dQ5StN57D44/Xttk\nSPFR5yBSh6FD4eqrFQwiNVHnIEVp+nS46CJYuBD23DN2NSL5pc5BpAZbtsCgQfDb3yoYRGqjcJCi\n85vfhBv5nHde7EpEkkvDSlJU5s+H006DOXM01yDFS8NKIlVUVobhpOHDFQwi9VE4SNEYNy7MN/zo\nR7ErEUk+DStJUVi+HHr0gOefD48ixUzDSiKAO/zwh3D55QoGkVxpy24peGPGwPvvw8SJsSsRSQ8N\nK0lBW7gQTj0VXnwRjjoqdjUiyaBhJSlqW7eGVdA//7mCQaSh1DlIwbr+enj9dXjiCbA6XyOJFJdc\nOgfNOUhBeuEFePDBsOOqgkGk4TSsJAVn+fIwnDR2LBx0UOxqRNJJ4SAFZcuWsGfSoEHQv3/sakTS\nS3MOUjDc4YorYNUqmDQp3BdaRLJpzkGKyn33wYwZ8M9/KhhEdpU6BykIL74YhpNmzIDOnWNXI5Js\nWucgRWHxYvjOd+ChhxQMIk1F4SCptmIF9OsHI0aERxFpGgoHSa21a+Gcc+CCC8LVSSLSdDTnIKm0\ncWPoFLp1g3vv1UI3kYbIZc5B4SCps2kTnHsutGsXVkHryiSRhtGEtBSctWvh61+HAw6A8eMVDCLN\nRT9akhqffAJnnhmGkv74RyjVKh2RZqNwkFT44AM4/XQ4+2y45x51DCLNTT9iknjz58Npp8Fll8Gv\nfqXJZ5F8UDhIoj32GPTpAzfdBEOGxK5GpHho1FYSafv2sLDtoYfg6afhxBNjVyRSXBQOkjhr1sDF\nF8P69TBrlu7JIBKDhpUkUaZMgR49oGtXmDpVwSASizoHSYR168KcwjPPhIVtffvGrkikuKlzkOie\nfx569oSKCnj9dQWDSBKoc5Bo3nkndAuvvQZ33w3f+EbsikRkB3UOkndr18LQoXDyyXDSSWEdg4JB\nJFkUDpI3n34aFrF16RLuw/DGGzBsGLRsGbsyEalO4SDNbuVKuOGGcJe2hQuhvBweeAAOPjh2ZSJS\nG4WDNAt3ePlluOSScFnqqlXwyithUdtRR8WuTkTqo/s5SJNauRImToT77w/3XbjiihAQBx4YuzIR\n2UE3+5G8WLUq7IE0cSLMnBnut3D55XDGGdo9VSSJFA7SLCorw+WnU6aEY86csJX2t78N/fvDXnvF\nrlBE6qJwkCaxY3HaSy+FY9o0aNMm3MP57LPDrqkKBJH0UDhIg23eDPPmhTCYOzcc//oXtG8Pp54a\njj59oFOn2JWKSGMlNhzMrB9wJ1ACjHX3kTWcMwr4OrARuMTd59RwjsKhESorYfnysEJ5x7F4cQiE\nd98N6xB69gwb4PXoAb16Qdu2sasWkaaSyHAwsxJgIXAWsAyYBVzg7vOrnNMfGOzu/c3sZOAud+9d\nw9dSOFThDhs2hAniFSvgww9h2bLwuONYujQEwL77wuGHh+Oww8IahO7d4cgjYY89Yv9NRKQ55RIO\nMfZWOglY7O5LAMxsAjAQmF/lnAHAHwDcfaaZtTGzdu7+cb6LbW7uYUx/y5YwpLN+/RePDRuy37du\nXbjnwapVsHr1zsfVq6G0FPbfP1w6esgh8KUvheOUU8Jj+/YhDPbeO/bfXESSLEY4HAIsrfL8A+Dk\nHM5pDzRrOPzpT7BkSbgLWUVFeKz6dk3vq+vcrVvDL/wtW+o+zMKr9VatYJ99wuTu3nvXfrRrF17h\n779/GO7Z8di2rbaiEJGmESMcch0Hqt7y1Ph5I0aM+PztsrIyysrKGlUUhFfpGzeGV9+lpeEXdmkp\nlJTsPKo+r+/tFi3C16jvKNXeuCLSjMrLyykvL2/Q58SYc+gNjHD3fpnnw4DKqpPSZnYfUO7uEzLP\nFwB9qg8rac5BRKThcplziLF+9VWgi5l1NLMWwHeBydXOmQx8Hz4Pk08Lcb5BRCSp8j6g4e4VZjYY\nmEK4lHWcu883s0GZj9/v7k+bWX8zWwxsAC7Nd50iIsVMi+BERIpMUoeVREQk4RQOIiKSReEgIiJZ\nFA4iIpJF4SAiIlkUDiIikkXhICIiWRQOIiKSReEgIiJZFA4iIpJF4ZAHDd0qN5Y01JmGGkF1NjXV\nmX8KhzxIyzdMGupMQ42gOpua6sw/hYOIiGRROIiISJbUb9kduwYRkTSqb8vuVIeDiIg0Dw0riYhI\nFoWDiIhkSXU4mNlJZvaKmc0xs1lm1it2TbUxs6vNbL6ZvWlmI2PXUxczu9bMKs2sbexaamJmt2b+\nLeea2aNm1jp2TVWZWT8zW2Bmi8xsaOx6amJmHcxsmpnNy3xPXhO7ptqYWUnmZ/yJ2LXUxszamNmk\nzPflW2bWO3ZNNTGzYZn/8zfM7BEz26O2c1MdDsAtwP+4+3HA/2aeJ46ZnQEMAHq4+zHAbZFLqpWZ\ndQC+CrwXu5Y6PAsc7e49gbeBYZHr+ZyZlQCjgX5AN+ACMzsqblU12gb81N2PBnoDVyW0ToAfA28B\nSZ4gvQt42t2PAnoA8yPXk8XMOgKXA8e7e3egBDi/tvPTHg7LgR2vGtsAyyLWUpcrgZvdfRuAu6+M\nXE9d7gB+FruIurj7c+5emXk6E2gfs55qTgIWu/uSzP/3BGBg5JqyuPtH7v5a5u31hF9mX4pbVTYz\naw/0B8YCdV5dE0umcz3N3ccDuHuFu38WuayarCW8KNjTzEqBPanjd2baw+G/gdvN7H3gVhL0CrKa\nLsDpZvZPMys3sxNjF1QTMxsIfODur8eupQEuA56OXUQVhwBLqzz/IPO+xMq8ojyOELRJ81vgOqCy\nvhMj6gSsNLMHzGy2mY0xsz1jF1Wdu68GbgfeBz4EPnX3qbWdX5qvwhrLzJ4D/qOGD90AXANc4+6P\nmdm3gfGEIZG8q6fOUmA/d++dmReZCByWz/p2qKfOYcDXqp6el6JqUEed17v7E5lzbgC2uvsjeS2u\nbkke+shiZnsDk4AfZzqIxDCzbwAr3H2OmZXFrqcOpcDxwGB3n2VmdxJeuP5v3LK+yMwOB34CdAQ+\nA/5qZhe5+59qOj/x4eDutf6yN7OH3f2szNNJhNYzinrqvBJ4NHPerMxk7/7uvipvBWbUVqeZHUN4\nBTTXzCAM1fzLzE5y9xV5LBGo+98TwMwuIQw39M1LQblbBnSo8rwDoXtIHDPbHfgb8LC7Px67nhqc\nAgwws/5AS2BfM3vI3b8fua7qPiB03LMyzycRwiFpTgRm7Pi9Y2aPEv6NawyHtA8rLTazPpm3zyRM\nTibR44T6MLOuQIsYwVAXd3/T3du5eyd370T4hj8+RjDUx8z6EYYaBrr75tj1VPMq0MXMOppZC+C7\nwOTINWWx8ApgHPCWu98Zu56auPv17t4h8/14PvCPBAYD7v4RsDTzsw1wFjAvYkm1WQD0NrNWmf//\nswgT/TVKfOdQjyuAezKXY23KPE+i8cB4M3sD2Aok7hu8BkkeHrkbaAE8l+lyXnb3H8UtKXD3CjMb\nDEwhXA0yzt0Td+UKcCpwMfC6mc3JvG+Yuz8Tsab6JPl78mrgT5kXBO8Al0auJ4u7zzWzhwgvYCqB\n2cDvaztf22eIiEiWtA8riYhIM1A4iIhIFoWDiIhkUTiIiEgWhYOIiGRROIiISBaFg4iIZFE4iIhI\nFoWDSBMys0GZG9PMMbN3zewfsWsSaQytkBZpBpn98v8BjHT3p2LXI9JQ6hxEmsco4HkFg6RV2jfe\nE0mczHbiHZKyGaBIYygcRJqQmZ0AXAucFrsWkV2hYSWRpnUVsB8wLTMpXeuWyCJJpglpERHJos5B\nRESyKBxERCSLwkFERLIoHEREJIvCQUREsigcREQki8JBRESyKBxERCTL/wM3Ucu2lNn0OgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11082a050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(z) :\n",
    "    return 1.0 / ( 1.0 + np.exp(-z) )\n",
    "z = np.arange( -7 , 7, 0.1 )\n",
    "phi_z = sigmoid(z)\n",
    "\n",
    "plt.plot( z, phi_z )\n",
    "plt.yticks( [ 0.0, 0.5, 1.0 ] )\n",
    "plt.ylim( -0.1, 1.1 )\n",
    "plt.xlabel( \"z\" )\n",
    "plt.ylabel( \"$\\phi(z)$\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit a logistic regression and predict the class's probability via `predict_proba`. Print out the probability of the first observation belonging to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.08753106e-04,   9.99285569e-01,   1.05678028e-04])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression( C = 1000.0, random_state = 0 )\n",
    "lr.fit( x_train_sd, y_train )\n",
    "pred_lr = lr.predict_proba( x_test_sd )\n",
    "pred_lr[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The concept for the parameter C. It's the inverse of regularization, so the smaller it is, the larger you penalize the model for getting too complex.\n",
    "\n",
    "- `Variance` Measures the consistency of the model. e.g. A **high variance** means that model is too complex and does not generalize well to unseen data\n",
    "- `Bias` Measures the systematic error that's not due to randomness. e.g. A **high bias** means that the model is underfitting. Meaning that the model is not complex enough to capture the pattern in the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Use `SGDClassifier` for online learning, which scales better with large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1 = SVC( kernel = \"linear\", C = 1.0, random_state = 0 )\n",
    "svm2 = SGDClassifier( loss = \"hinge\" ) # loss = \"log\" for logistic regression\n",
    "svm1.fit( x_train_sd, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Radial kernel ( there're other types, but this one is the most commonly used ) to solve non-linear classification problem.\n",
    "\n",
    "[Link](https://www.quora.com/What-are-C-and-gamma-with-regards-to-a-support-vector-machine) to a few slightly *more* detailed explanation regarding the parameter gamma and C on Quora.\n",
    "\n",
    "- `C` : A large C gives you low bias and high variance, since the model model will aim to classify all the data points correctly, thus have the higher risk of overfitting the training data.\n",
    "- `gamma` The parameter that controls the radial kernel. A small value will give a softer decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC( kernel = \"rbf\", random_state = 0, gamma = 0.1, C = 10.0 )\n",
    "svm.fit( x_train_sd, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Note that Although feature scaling may be desired for visualization and model comparision purposes. Feature scaling is not a requirement for tree-type algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier( criterion = \"entropy\", max_depth = 3, random_state = 0 )\n",
    "tree.fit(  x_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @n_jobs = parallelize the model training using multiple cores\n",
    "forest = RandomForestClassifier( criterion = \"entropy\", n_estimators = 10, random_state = 1, n_jobs = 2 )\n",
    "forest.fit( x_train, y_train )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors\n",
    "\n",
    "The algorithm is very susceptible to the *curse of dimensionality*. Meaning that due to the high dimensionality, even the closest neighbors become too far away to give a good estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier( n_neighbors = 5 ) \n",
    "knn.fit( x_train_sd, y_train )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
